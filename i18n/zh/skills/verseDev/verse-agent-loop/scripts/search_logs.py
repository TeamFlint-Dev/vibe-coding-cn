#!/usr/bin/env python3
"""
æ—¥å¿—æ£€ç´¢å·¥å…· - æœç´¢å’Œè¿‡æ»¤å†å²æ—¥å¿—

æ”¯æŒæŒ‰å…³é”®è¯ã€ä»»åŠ¡IDã€çŠ¶æ€ã€æ—¶é—´èŒƒå›´æ£€ç´¢æ—¥å¿—ã€‚
"""

import argparse
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Optional

from utils import parse_date_range


def search_logs(
    logs_dir: Path,
    keyword: Optional[str] = None,
    task_id: Optional[str] = None,
    status: Optional[str] = None,
    date_range: Optional[str] = None,
    output_file: Optional[str] = None,
) -> list:
    """
    æœç´¢æ—¥å¿—
    
    Args:
        logs_dir: æ—¥å¿—ç›®å½•
        keyword: å…³é”®è¯æœç´¢
        task_id: ä»»åŠ¡IDç²¾ç¡®åŒ¹é…
        status: çŠ¶æ€è¿‡æ»¤ (completed/escalated)
        date_range: æ—¶é—´èŒƒå›´ (7d/2w/1m)
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ¹é…çš„æ—¥å¿—æ¡ç›®åˆ—è¡¨
    """
    results = []
    
    # ç¡®å®šæœç´¢èŒƒå›´
    search_dirs = []
    
    if task_id:
        # ç²¾ç¡®åŒ¹é…ä»»åŠ¡ID
        for subdir in ["active", "archive", "escalation"]:
            task_path = logs_dir / subdir / task_id
            if task_path.exists():
                search_dirs.append(task_path)
            # æ£€æŸ¥å½’æ¡£ç›®å½•
            archive_path = logs_dir / "archive"
            if archive_path.exists():
                for month_dir in archive_path.iterdir():
                    task_archive = month_dir / task_id
                    if task_archive.exists():
                        search_dirs.append(task_archive)
    else:
        # æœç´¢æ‰€æœ‰ç›®å½•
        if status == "escalated":
            search_dirs.append(logs_dir / "escalation")
        elif status == "completed":
            search_dirs.append(logs_dir / "active")
            search_dirs.append(logs_dir / "archive")
        else:
            search_dirs.extend([
                logs_dir / "active",
                logs_dir / "archive",
                logs_dir / "escalation",
            ])
    
    # æ—¶é—´èŒƒå›´è¿‡æ»¤
    start_time, end_time = None, None
    if date_range:
        start_time, end_time = parse_date_range(date_range)
    
    # æœç´¢
    for search_dir in search_dirs:
        if not search_dir.exists():
            continue
        
        for item in search_dir.rglob("*"):
            if not item.is_file():
                continue
            
            # æ—¶é—´è¿‡æ»¤
            if start_time and end_time:
                mtime = datetime.fromtimestamp(item.stat().st_mtime)
                if not (start_time <= mtime <= end_time):
                    continue
            
            # å…³é”®è¯æœç´¢
            if keyword:
                try:
                    content = item.read_text(encoding="utf-8")
                    if keyword.lower() not in content.lower():
                        continue
                    
                    # æå–åŒ¹é…çš„ä¸Šä¸‹æ–‡
                    matches = find_keyword_context(content, keyword)
                    if matches:
                        results.append({
                            "file": str(item),
                            "task_id": extract_task_id(item),
                            "matches": matches,
                        })
                except Exception:
                    continue
            else:
                # æ— å…³é”®è¯ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯
                results.append({
                    "file": str(item),
                    "task_id": extract_task_id(item),
                    "size": item.stat().st_size,
                    "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat(),
                })
    
    # è¾“å‡ºç»“æœ
    if output_file:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return results


def find_keyword_context(content: str, keyword: str, context_lines: int = 2) -> list:
    """æŸ¥æ‰¾å…³é”®è¯åŠå…¶ä¸Šä¸‹æ–‡"""
    matches = []
    lines = content.split("\n")
    keyword_lower = keyword.lower()
    
    for i, line in enumerate(lines):
        if keyword_lower in line.lower():
            # è·å–ä¸Šä¸‹æ–‡
            start = max(0, i - context_lines)
            end = min(len(lines), i + context_lines + 1)
            context = lines[start:end]
            
            matches.append({
                "line_number": i + 1,
                "line": line.strip(),
                "context": "\n".join(context),
            })
    
    return matches


def extract_task_id(file_path: Path) -> str:
    """ä»æ–‡ä»¶è·¯å¾„æå–ä»»åŠ¡ID"""
    for part in file_path.parts:
        if part.startswith("REQ-"):
            return part
    return ""


def print_results(results: list, verbose: bool = False):
    """æ‰“å°æœç´¢ç»“æœ"""
    if not results:
        print("æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
        return
    
    print(f"\næ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹:\n")
    
    for result in results:
        task_id = result.get("task_id", "N/A")
        file_path = result.get("file", "")
        
        print(f"ğŸ“„ {task_id}: {file_path}")
        
        if verbose and "matches" in result:
            for match in result["matches"][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
                print(f"   è¡Œ {match['line_number']}: {match['line'][:80]}...")
            if len(result["matches"]) > 3:
                print(f"   ... è¿˜æœ‰ {len(result['matches']) - 3} ä¸ªåŒ¹é…")
        
        print()


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="Verse Agent Loop æ—¥å¿—æ£€ç´¢å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # æŒ‰å…³é”®è¯æ£€ç´¢æœ€è¿‘7å¤©
    python search_logs.py --keyword "äº‹ä»¶æ–¹å‘" --last 7d
    
    # æŒ‰ä»»åŠ¡IDæ£€ç´¢
    python search_logs.py --task REQ-20251229-001
    
    # æ£€ç´¢å‡çº§çš„ä»»åŠ¡
    python search_logs.py --status escalated
    
    # è¾“å‡ºåˆ°æ–‡ä»¶
    python search_logs.py --keyword "ç¼–è¯‘é”™è¯¯" --output result.json
        """
    )
    
    parser.add_argument("-k", "--keyword", type=str,
                        help="å…³é”®è¯æœç´¢")
    parser.add_argument("-t", "--task", type=str,
                        help="ä»»åŠ¡IDç²¾ç¡®åŒ¹é…")
    parser.add_argument("-s", "--status", type=str,
                        choices=["completed", "escalated"],
                        help="æŒ‰çŠ¶æ€è¿‡æ»¤")
    parser.add_argument("-l", "--last", type=str, default="7d",
                        help="æ—¶é—´èŒƒå›´ (ä¾‹: 7d, 2w, 1m)")
    parser.add_argument("-o", "--output", type=str,
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="æ˜¾ç¤ºè¯¦ç»†åŒ¹é…å†…å®¹")
    
    args = parser.parse_args()
    
    # ç¡®å®šæ—¥å¿—ç›®å½•
    logs_dir = Path(__file__).parent.parent / "logs"
    
    if not logs_dir.exists():
        print(f"é”™è¯¯: æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {logs_dir}")
        return
    
    # æ‰§è¡Œæœç´¢
    results = search_logs(
        logs_dir=logs_dir,
        keyword=args.keyword,
        task_id=args.task,
        status=args.status,
        date_range=args.last,
        output_file=args.output,
    )
    
    # æ‰“å°ç»“æœ
    if not args.output:
        print_results(results, args.verbose)


if __name__ == "__main__":
    main()
