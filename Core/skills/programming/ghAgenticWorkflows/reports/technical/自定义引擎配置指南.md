# 自定义引擎配置指南

> 调研日期：2026-01-03
> 调研来源：gh-aw 官方 Schema、官方文档、示例工作流

## 概述

GitHub Agentic Workflows (gh-aw) 的 `engine` 字段用于指定执行工作流 Markdown 内容的 AI 处理器。本文档详细说明如何配置引擎，特别是如何使用自定义引擎集成第三方 AI 服务（如 DeepSeek）。

---

## 1. 支持的引擎类型

| 引擎 ID | 状态 | 说明 |
|---------|------|------|
| `copilot` | ✅ **默认推荐** | GitHub Copilot CLI，无需显式配置 |
| `claude` | ⚠️ 实验性 | Claude Code，需 `engine: claude` |
| `codex` | ⚠️ 实验性 | OpenAI Codex CLI |
| `custom` | ✅ **可用** | 用户自定义 GitHub Actions 步骤 |

**重要**：`copilot` 是默认引擎，不需要显式声明。只有使用其他引擎时才需要配置 `engine` 字段。

---

## 2. Engine 配置格式

### 2.1 简单格式（字符串）

```yaml
engine: copilot  # 或 claude, codex, custom
```

### 2.2 对象格式（详细配置）

```yaml
engine:
  id: copilot              # 必填：引擎标识符
  version: beta            # 可选：action 版本
  model: gpt-5             # 可选：LLM 模型（仅部分引擎支持）
  max-turns: 10            # 可选：最大迭代次数（仅 claude 支持）
  concurrency:             # 可选：并发控制
    group: "gh-aw-custom"
    cancel-in-progress: false
  env:                     # 可选：环境变量
    DEBUG_MODE: "true"
    OPENAI_API_KEY: ${{ secrets.MY_KEY }}
  args: ["--verbose"]      # 可选：CLI 参数
  error_patterns: []       # 可选：自定义错误匹配
```

### 2.3 各字段说明

| 字段 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `id` | string | ✅ 对象格式时必填 | 引擎标识符：`copilot`, `claude`, `codex`, `custom` |
| `version` | string/number | ❌ | action 版本，如 `beta`, `stable`, `20` |
| `model` | string | ❌ | LLM 模型名称，如 `claude-3-5-sonnet-20241022` |
| `max-turns` | integer | ❌ | 最大迭代次数（**仅 claude 引擎支持**） |
| `concurrency` | string/object | ❌ | 并发控制，默认 `gh-aw-{engine-id}` |
| `env` | object | ❌ | 传递给引擎的环境变量 |
| `args` | array | ❌ | 传递给 CLI 的额外参数 |
| `steps` | array | ❌ | **仅 custom 引擎**：自定义 GitHub Actions 步骤 |
| `error_patterns` | array | ❌ | 自定义错误模式匹配 |
| `config` | string | ❌ | **仅 codex 引擎**：附加 TOML 配置 |
| `user-agent` | string | ❌ | **仅 codex 引擎**：自定义 User-Agent |

---

## 3. Custom Engine 详解

当内置引擎无法满足需求时（如使用 DeepSeek、Gemini 等），使用 `custom` 引擎自定义执行逻辑。

### 3.1 Custom Engine 结构

```yaml
engine:
  id: custom
  env:
    MY_VAR: "value"
  steps:
    - name: Step 1
      run: echo "Hello"
    - name: Step 2
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
```

### 3.2 可用环境变量

Custom Engine 的 steps 中自动可用以下环境变量：

| 变量 | 说明 |
|------|------|
| `$GH_AW_PROMPT` | 工作流 Markdown 内容的文件路径 (`/tmp/gh-aw/aw-prompts/prompt.txt`) |
| `$GH_AW_SAFE_OUTPUTS` | Safe outputs 输出文件路径 |
| `$GH_AW_MAX_TURNS` | 配置的 `max-turns` 值 |
| `$GH_AW_MCP_CONFIG` | MCP 服务器配置文件路径（如果配置了 MCP） |

### 3.3 读取 Prompt 内容

```bash
# 在 custom engine 的 step 中读取 prompt
cat "$GH_AW_PROMPT"
```

---

## 4. 使用 DeepSeek 作为引擎

### 4.1 核心原理

DeepSeek API 兼容 OpenAI API 格式，可通过 OpenAI SDK 调用：

- **API Base**: `https://api.deepseek.com/v1`
- **模型**: `deepseek-chat`, `deepseek-coder`
- **认证**: 通过 `DEEPSEEK_API_KEY` 环境变量

### 4.2 方案 A：创建共享配置（推荐）

创建 `.github/workflows/shared/deepseek.md`：

```yaml
---
engine:
  id: custom
  env:
    GH_AW_AGENT_MODEL: "deepseek-chat"
    GH_AW_AGENT_API_BASE: "https://api.deepseek.com/v1"
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install OpenAI SDK
      run: pip install openai

    - name: Run DeepSeek Agent
      run: |
        python3 << 'AGENT_SCRIPT'
        import os
        from openai import OpenAI

        # 初始化 DeepSeek 客户端（兼容 OpenAI API）
        client = OpenAI(
            api_key=os.environ["DEEPSEEK_API_KEY"],
            base_url=os.environ.get("GH_AW_AGENT_API_BASE", "https://api.deepseek.com/v1")
        )

        # 读取工作流 prompt
        with open(os.environ["GH_AW_PROMPT"], "r") as f:
            prompt_content = f.read()

        # 调用 DeepSeek
        response = client.chat.completions.create(
            model=os.environ.get("GH_AW_AGENT_MODEL", "deepseek-chat"),
            messages=[
                {
                    "role": "system",
                    "content": "You are a skilled software engineer. Follow instructions precisely."
                },
                {"role": "user", "content": prompt_content}
            ],
            temperature=0.1,
            max_tokens=4096
        )

        result = response.choices[0].message.content
        print("=== DeepSeek Response ===")
        print(result)

        # 如果配置了 safe-outputs，写入结果
        safe_outputs_path = os.environ.get("GH_AW_SAFE_OUTPUTS")
        if safe_outputs_path:
            with open(safe_outputs_path, "w") as f:
                f.write(result)
        AGENT_SCRIPT
      env:
        GH_AW_PROMPT: ${{ env.GH_AW_PROMPT }}
        GH_AW_SAFE_OUTPUTS: ${{ env.GH_AW_SAFE_OUTPUTS }}
        GH_AW_AGENT_MODEL: ${{ env.GH_AW_AGENT_MODEL }}
        GH_AW_AGENT_API_BASE: ${{ env.GH_AW_AGENT_API_BASE }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
---

<!--
DeepSeek Custom Engine for GitHub Agentic Workflows

## 使用方法

在工作流中导入此共享配置：

```yaml
---
imports:
  - shared/deepseek.md
permissions:
  contents: read
---

# 你的任务指令...
```

## 配置要求

1. 在仓库 Settings → Secrets 中配置 `DEEPSEEK_API_KEY`
2. 可选覆盖模型：

   ```yaml
   engine:
     env:
       GH_AW_AGENT_MODEL: "deepseek-coder"
   ```

-->
```yaml

### 4.3 方案 B：直接在工作流中配置

```yaml
---
name: DeepSeek Task Runner

on:
  workflow_dispatch:
    inputs:
      task:
        description: "Task to execute"
        required: true

permissions:
  contents: read

engine:
  id: custom
  env:
    DEEPSEEK_MODEL: "deepseek-chat"
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: pip install openai

    - name: Execute with DeepSeek
      run: |
        python3 << 'EOF'
        import os
        from openai import OpenAI

        client = OpenAI(
            api_key=os.environ["DEEPSEEK_API_KEY"],
            base_url="https://api.deepseek.com/v1"
        )

        with open(os.environ["GH_AW_PROMPT"], "r") as f:
            prompt = f.read()

        response = client.chat.completions.create(
            model=os.environ.get("DEEPSEEK_MODEL", "deepseek-chat"),
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ]
        )

        print(response.choices[0].message.content)
        EOF
      env:
        GH_AW_PROMPT: ${{ env.GH_AW_PROMPT }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        DEEPSEEK_MODEL: ${{ env.DEEPSEEK_MODEL }}
---

# Task Instructions

Execute the following task: ${{ inputs.task }}
```

### 4.4 方案 C：基于现有共享配置

gh-aw 已有几个可参考的共享配置：

| 共享配置 | 路径 | 适用场景 |
|---------|------|---------|
| OpenCode | `shared/opencode.md` | 支持多种模型提供商 |
| GenAIScript | `shared/genaiscript.md` | Microsoft 的 AI 脚本框架 |
| Actions AI Inference | `shared/actions-ai-inference.md` | GitHub 官方 AI 推理 Action |

**使用 OpenCode 集成 DeepSeek**：

```yaml
---
imports:
  - shared/opencode.md

engine:
  env:
    GH_AW_AGENT_MODEL: "deepseek/deepseek-chat"
---

# 你的任务指令...
```

---

## 5. 完整示例：DeepSeek 代码审查工作流

```yaml
---
name: DeepSeek Code Review
description: AI-powered code review using DeepSeek

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write

engine:
  id: custom
  env:
    DEEPSEEK_MODEL: "deepseek-coder"
  steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: pip install openai

    - name: Get PR diff
      id: diff
      run: |
        git diff origin/${{ github.base_ref }}...origin/${{ github.head_ref }} > /tmp/pr_diff.txt
        echo "diff_file=/tmp/pr_diff.txt" >> $GITHUB_OUTPUT

    - name: Run DeepSeek Review
      run: |
        python3 << 'REVIEW_SCRIPT'
        import os
        import json
        from openai import OpenAI

        client = OpenAI(
            api_key=os.environ["DEEPSEEK_API_KEY"],
            base_url="https://api.deepseek.com/v1"
        )

        # 读取 prompt 和 diff
        with open(os.environ["GH_AW_PROMPT"], "r") as f:
            instructions = f.read()

        with open("/tmp/pr_diff.txt", "r") as f:
            diff_content = f.read()

        full_prompt = f"{instructions}\n\n## PR Diff:\n```diff\n{diff_content}\n```"

        response = client.chat.completions.create(
            model=os.environ.get("DEEPSEEK_MODEL", "deepseek-coder"),
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert code reviewer. Provide constructive feedback."
                },
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.2,
            max_tokens=4096
        )

        result = response.choices[0].message.content

        # 写入 safe-outputs
        safe_outputs = os.environ.get("GH_AW_SAFE_OUTPUTS")
        if safe_outputs:
            output = {"type": "add_comment", "body": result}
            with open(safe_outputs, "w") as f:
                json.dump(output, f)

        print(result)
        REVIEW_SCRIPT
      env:
        GH_AW_PROMPT: ${{ env.GH_AW_PROMPT }}
        GH_AW_SAFE_OUTPUTS: ${{ env.GH_AW_SAFE_OUTPUTS }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        DEEPSEEK_MODEL: ${{ env.DEEPSEEK_MODEL }}

safe-outputs:
  add-comment:
    max: 1
    target: triggering
---

# Code Review Instructions

You are reviewing a pull request. Analyze the code changes and provide:

1. **Summary**: Brief overview of the changes
2. **Issues**: Potential bugs, security concerns, or anti-patterns
3. **Suggestions**: Improvements for code quality and maintainability
4. **Verdict**: Whether this PR is ready to merge

Be constructive and specific in your feedback.
```

---

## 6. 能力边界

### 6.1 能做的事（绿灯区）

| 能力 | 说明 |
|------|------|
| 使用 Custom Engine | 完全自定义 GitHub Actions 步骤 |
| 传递环境变量 | 通过 `engine.env` 配置 |
| 访问 Secrets | `${{ secrets.DEEPSEEK_API_KEY }}` |
| 读取 Prompt | 通过 `$GH_AW_PROMPT` 环境变量 |
| 写入 Safe Outputs | 通过 `$GH_AW_SAFE_OUTPUTS` 写入 JSON |
| 导入共享配置 | 使用 `imports:` 复用引擎配置 |

### 6.2 不能做的事（红灯区）

| 限制 | 说明 |
|------|------|
| 内置 DeepSeek 引擎 | gh-aw 不直接支持，必须用 custom |
| Custom Engine 使用 MCP | 需手动处理 `$GH_AW_MCP_CONFIG`，无自动集成 |
| max-turns 限制 | 仅 claude 引擎支持，custom 需自行实现 |
| 网络防火墙 (AWF) | 仅 copilot 引擎支持 |

### 6.3 有条件能做的事（黄灯区）

| 能力 | 条件 |
|------|------|
| MCP 服务器集成 | 需在脚本中手动解析 `$GH_AW_MCP_CONFIG` |
| 多轮对话 | 需在 custom steps 中自行实现循环逻辑 |
| 错误重试 | 需在脚本中自行实现 |

---

## 7. 常见问题

### Q1: 如何覆盖共享配置中的模型？

在你的工作流中重新定义 `engine.env`：

```yaml
---
imports:
  - shared/deepseek.md

engine:
  env:
    GH_AW_AGENT_MODEL: "deepseek-coder"  # 覆盖默认的 deepseek-chat
---
```

### Q2: Safe Outputs 格式是什么？

写入 `$GH_AW_SAFE_OUTPUTS` 的 JSON 格式：

```json
{"type": "add_comment", "body": "Review result..."}
{"type": "create_issue", "title": "Bug found", "body": "Description..."}
```

### Q3: 如何调试 Custom Engine？

1. 在 steps 中添加调试输出：

   ```yaml
   - name: Debug
     run: |
       echo "Prompt file: $GH_AW_PROMPT"
       cat "$GH_AW_PROMPT"
   ```

2. 查看 Actions 运行日志

### Q4: 支持哪些 DeepSeek 模型？

| 模型 | 用途 |
|------|------|
| `deepseek-chat` | 通用对话，适合大多数任务 |
| `deepseek-coder` | 代码相关任务，更适合代码审查、生成 |

---

## 8. 参考资料

- [gh-aw 官方文档](Core/skills/programming/ghAgenticWorkflows/shared/gh-aw-raw/aw/github-agentic-workflows.md)
- [OpenCode 共享配置](Core/skills/programming/ghAgenticWorkflows/shared/gh-aw-raw/workflows/shared/opencode.md)
- [GenAIScript 共享配置](Core/skills/programming/ghAgenticWorkflows/shared/gh-aw-raw/workflows/shared/genaiscript.md)
- [DeepSeek API 文档](https://platform.deepseek.com/api-docs/)

---

## 更新日志

| 日期 | 变更 |
|------|------|
| 2026-01-03 | 初始版本，完成 Custom Engine 与 DeepSeek 集成调研 |
