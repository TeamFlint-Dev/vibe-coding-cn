# ç´¢å¼•æœºåˆ¶è¯¦è§£ - è‡ªè¿›åŒ–ç¼–ç æ¡†æ¶

## ğŸ¯ ç´¢å¼•æœºåˆ¶æ€»è§ˆ

ç´¢å¼•æ˜¯æ¡†æ¶è¿›åŒ–çš„**æ ¸å¿ƒ**ï¼Œå®ƒå®šä¹‰äº†"åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ï¼Œåº”è¯¥ç»™Agentçœ‹ä»€ä¹ˆ"ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ç´¢å¼•é…ç½®æ–‡ä»¶ï¼ˆè¿›åŒ–æ ¸å¿ƒï¼‰         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  feature-weights.json   ç‰¹å¾æƒé‡ç´¢å¼•    â”‚
â”‚  example-index.json     æ¡ˆä¾‹é€‰æ‹©ç´¢å¼•    â”‚
â”‚  pattern-index.json     æ¨¡å¼å¼•ç”¨ç´¢å¼•    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ é©±åŠ¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          æ¸è¿›å¼æŠ«éœ²ç­–ç•¥                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ ¹æ®ç´¢å¼•æƒé‡ï¼Œé€‰æ‹©æ€§å±•ç¤ºä¸Šä¸‹æ–‡ç»™Agent  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ å½±å“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Agentäº§å‡ºè´¨é‡                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ åé¦ˆ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Learneråˆ†æå¹¶æ›´æ–°ç´¢å¼•           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‡ feature-weights.json - ç‰¹å¾æƒé‡ç´¢å¼•

### æ–‡ä»¶ç»“æ„

**ä½ç½®**ï¼š`.state/indices/feature-weights.json`

**æ ¼å¼**ï¼š

```json
{
  "version": "1.2.0",
  "last_updated": "2026-01-15T10:30:00Z",
  "learning_rate": 0.20,
  "weights": {
    "zero_coupling": {
      "value": 0.92,
      "history": [0.50, 0.63, 0.75, 0.85, 0.92],
      "correlation": 0.92,
      "confidence": 0.95
    },
    "modularity": {
      "value": 0.85,
      "history": [0.50, 0.57, 0.68, 0.78, 0.85],
      "correlation": 0.85,
      "confidence": 0.90
    },
    "naming": {
      "value": 0.65,
      "history": [0.50, 0.53, 0.58, 0.62, 0.65],
      "correlation": 0.65,
      "confidence": 0.80
    },
    "error_handling": {
      "value": 0.60,
      "history": [0.50, 0.52, 0.55, 0.58, 0.60],
      "correlation": 0.55,
      "confidence": 0.75
    },
    "testability": {
      "value": 0.58,
      "history": [0.50, 0.51, 0.53, 0.56, 0.58],
      "correlation": 0.50,
      "confidence": 0.70
    },
    "performance": {
      "value": 0.45,
      "history": [0.50, 0.48, 0.46, 0.45, 0.45],
      "correlation": 0.20,
      "confidence": 0.60
    },
    "comments": {
      "value": 0.35,
      "history": [0.50, 0.45, 0.40, 0.37, 0.35],
      "correlation": 0.10,
      "confidence": 0.55
    }
  },
  "metadata": {
    "cycles_analyzed": 50,
    "last_significant_change": "2026-01-12T15:00:00Z",
    "converged": false,
    "convergence_target": 0.05
  }
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | è¯´æ˜ | èŒƒå›´ | ç”¨é€” |
|-----|------|------|------|
| `value` | å½“å‰æƒé‡å€¼ | 0.20-0.95 | å†³å®šæŠ«éœ²ç¨‹åº¦ |
| `history` | å†å²æƒé‡å€¼ | æ•°ç»„ | è¿½è¸ªè¿›åŒ–è½¨è¿¹ |
| `correlation` | ä¸è´¨é‡çš„ç›¸å…³ç³»æ•° | -1 åˆ° 1 | å­¦ä¹ ä¾æ® |
| `confidence` | æƒé‡ç½®ä¿¡åº¦ | 0-1 | æƒé‡å¯ä¿¡ç¨‹åº¦ |

### åˆå§‹åŒ–

**é¦–æ¬¡åˆ›å»º**ï¼ˆæ‰€æœ‰æƒé‡éšæœºï¼‰ï¼š

```json
{
  "version": "1.0.0",
  "learning_rate": 0.20,
  "weights": {
    "zero_coupling": {"value": 0.50, "history": [0.50]},
    "modularity": {"value": 0.50, "history": [0.50]},
    "naming": {"value": 0.50, "history": [0.50]},
    "error_handling": {"value": 0.50, "history": [0.50]},
    "testability": {"value": 0.50, "history": [0.50]},
    "performance": {"value": 0.50, "history": [0.50]},
    "comments": {"value": 0.50, "history": [0.50]}
  }
}
```

**ä½¿ç”¨é¢†åŸŸçŸ¥è¯†åˆå§‹åŒ–**ï¼ˆå¯é€‰ï¼‰ï¼š

```json
{
  "weights": {
    "zero_coupling": {"value": 0.75, "history": [0.75]},
    "modularity": {"value": 0.70, "history": [0.70]},
    "naming": {"value": 0.60, "history": [0.60]},
    ...
  }
}
```

### å¦‚ä½•ä»åé¦ˆä¸­ä¼˜åŒ–

#### æ›´æ–°ç®—æ³•

```python
def update_feature_weights(current_weights, correlations, learning_rate=0.20):
    """
    æ ¹æ®ç›¸å…³æ€§æ›´æ–°ç‰¹å¾æƒé‡
    
    Args:
        current_weights: å½“å‰æƒé‡å­—å…¸
        correlations: ç‰¹å¾ä¸è´¨é‡çš„ç›¸å…³ç³»æ•°
        learning_rate: å­¦ä¹ ç‡ (0-1)
    
    Returns:
        æ›´æ–°åçš„æƒé‡å­—å…¸
    """
    new_weights = {}
    
    for feature, data in current_weights['weights'].items():
        current_value = data['value']
        correlation = correlations[feature]
        
        # å°†ç›¸å…³ç³»æ•° [-1, 1] æ˜ å°„åˆ° [0, 1]
        normalized_corr = (correlation + 1) / 2
        
        # åŠ æƒç§»åŠ¨å¹³å‡
        new_value = (
            current_value * (1 - learning_rate) +
            normalized_corr * learning_rate
        )
        
        # é™åˆ¶èŒƒå›´
        MIN_WEIGHT = 0.20  # ä¸å®Œå…¨å¿½ç•¥
        MAX_WEIGHT = 0.95  # ä¸è¿‡åº¦ä¾èµ–
        new_value = max(MIN_WEIGHT, min(MAX_WEIGHT, new_value))
        
        # æ›´æ–°å†å²
        history = data['history'] + [new_value]
        if len(history) > 10:  # åªä¿ç•™æœ€è¿‘10æ¬¡
            history = history[-10:]
        
        new_weights[feature] = {
            'value': round(new_value, 2),
            'history': history,
            'correlation': correlation,
            'confidence': calculate_confidence(history)
        }
    
    return new_weights

def calculate_confidence(history):
    """
    æ ¹æ®å†å²ç¨³å®šæ€§è®¡ç®—ç½®ä¿¡åº¦
    å†å²è¶Šç¨³å®šï¼Œç½®ä¿¡åº¦è¶Šé«˜
    """
    if len(history) < 3:
        return 0.50  # æ•°æ®ä¸è¶³
    
    variance = calculate_variance(history[-5:])
    
    # æ–¹å·®å° â†’ ç½®ä¿¡åº¦é«˜
    confidence = 1.0 - min(1.0, variance * 10)
    return round(confidence, 2)
```

#### ç›¸å…³æ€§è®¡ç®—

```python
def calculate_correlations(experiences):
    """
    è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸è´¨é‡åˆ†æ•°çš„ç›¸å…³æ€§
    
    Args:
        experiences: å†å²è¿è¡Œæ•°æ®åˆ—è¡¨
    
    Returns:
        ç‰¹å¾ç›¸å…³ç³»æ•°å­—å…¸
    """
    features = ['zero_coupling', 'modularity', 'naming', ...]
    correlations = {}
    
    for feature in features:
        # æå–ç‰¹å¾åˆ†æ•°å’Œè´¨é‡åˆ†æ•°
        feature_scores = [
            exp['analysis']['features'][feature]
            for exp in experiences
        ]
        quality_scores = [
            exp['output']['quality_score']
            for exp in experiences
        ]
        
        # è®¡ç®—Pearsonç›¸å…³ç³»æ•°
        corr = pearson_correlation(feature_scores, quality_scores)
        correlations[feature] = corr
    
    return correlations

def pearson_correlation(x, y):
    """è®¡ç®—Pearsonç›¸å…³ç³»æ•°"""
    n = len(x)
    mean_x = sum(x) / n
    mean_y = sum(y) / n
    
    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
    denominator_x = sum((x[i] - mean_x) ** 2 for i in range(n)) ** 0.5
    denominator_y = sum((y[i] - mean_y) ** 2 for i in range(n)) ** 0.5
    
    if denominator_x == 0 or denominator_y == 0:
        return 0
    
    return numerator / (denominator_x * denominator_y)
```

#### æ›´æ–°ç¤ºä¾‹

```python
# åˆå§‹çŠ¶æ€
current = {
    "weights": {
        "zero_coupling": {"value": 0.50, "history": [0.50]},
        "naming": {"value": 0.50, "history": [0.50]}
    }
}

# åˆ†æ5è½®å¾ªç¯åçš„ç›¸å…³æ€§
correlations = {
    "zero_coupling": 0.92,  # å¼ºç›¸å…³
    "naming": 0.30          # å¼±ç›¸å…³
}

# æ›´æ–°æƒé‡ï¼ˆlearning_rate = 0.20ï¼‰
new_weights = update_feature_weights(current, correlations, 0.20)

# ç»“æœ
# {
#   "zero_coupling": {
#     "value": 0.63,  # 0.50 * 0.8 + 0.96 * 0.2 = 0.59
#     "history": [0.50, 0.63],
#     "correlation": 0.92
#   },
#   "naming": {
#     "value": 0.48,  # 0.50 * 0.8 + 0.65 * 0.2 = 0.53
#     "history": [0.50, 0.48],
#     "correlation": 0.30
#   }
# }
```

### å¦‚ä½•å½±å“æŠ«éœ²

**Producerè¯»å–æƒé‡ï¼Œå†³å®šæŠ«éœ²ç­–ç•¥**ï¼š

```python
def disclose_context(feature_weights, knowledge_base):
    """
    æ ¹æ®ç‰¹å¾æƒé‡æ¸è¿›å¼æŠ«éœ²ä¸Šä¸‹æ–‡
    """
    context = []
    
    # æŒ‰æƒé‡é™åºæ’åºç‰¹å¾
    sorted_features = sorted(
        feature_weights['weights'].items(),
        key=lambda x: x[1]['value'],
        reverse=True
    )
    
    for feature, data in sorted_features:
        weight = data['value']
        
        if weight >= 0.85:
            # å®Œæ•´æŠ«éœ²
            pattern = knowledge_base.get_pattern(feature, level='full')
            examples = knowledge_base.get_examples(feature, count=3, quality='excellent')
            context.append({
                'feature': feature,
                'pattern': pattern,
                'examples': examples,
                'tokens': len(pattern) + sum(len(ex) for ex in examples)
            })
            
        elif weight >= 0.70:
            # è¯¦ç»†æ‘˜è¦
            pattern = knowledge_base.get_pattern(feature, level='summary')
            examples = knowledge_base.get_examples(feature, count=2, quality='excellent')
            context.append({
                'feature': feature,
                'pattern': pattern,
                'examples': examples
            })
            
        elif weight >= 0.50:
            # ç®€è¦æåŠ
            pattern = knowledge_base.get_pattern(feature, level='brief')
            context.append({
                'feature': feature,
                'pattern': pattern
            })
        
        # weight < 0.50: ä¸æŠ«éœ²
    
    return context
```

## ğŸ“š example-index.json - æ¡ˆä¾‹é€‰æ‹©ç´¢å¼•

### æ–‡ä»¶ç»“æ„

**ä½ç½®**ï¼š`.state/indices/example-index.json`

**æ ¼å¼**ï¼š

```json
{
  "version": "1.0.0",
  "last_updated": "2026-01-15T10:30:00Z",
  "by_feature": {
    "zero_coupling": {
      "excellent": [
        {
          "file": "HealthComponent.verse",
          "quality": 0.87,
          "usage_count": 12,
          "avg_result_quality": 0.85,
          "last_used": "2026-01-14T10:00:00Z"
        },
        {
          "file": "AttackSystem.verse",
          "quality": 0.85,
          "usage_count": 10,
          "avg_result_quality": 0.83
        },
        {
          "file": "InventoryManager.verse",
          "quality": 0.82,
          "usage_count": 8,
          "avg_result_quality": 0.80
        }
      ],
      "average": [
        {
          "file": "OldHealthScript.verse",
          "quality": 0.65,
          "usage_count": 2,
          "avg_result_quality": 0.63
        }
      ]
    },
    "modularity": {
      "excellent": [...]
    }
  },
  "by_scenario": {
    "player_management": [
      {
        "file": "HealthComponent.verse",
        "relevance": 0.95,
        "usage_count": 15
      },
      {
        "file": "InventoryManager.verse",
        "relevance": 0.90,
        "usage_count": 12
      }
    ],
    "combat_system": [...]
  },
  "metadata": {
    "total_examples": 45,
    "excellent_count": 28,
    "average_count": 17
  }
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | è¯´æ˜ | ç”¨é€” |
|-----|------|------|
| `by_feature` | æŒ‰ç‰¹å¾åˆ†ç±»çš„æ¡ˆä¾‹ | Produceræ ¹æ®é«˜æƒé‡ç‰¹å¾æŸ¥æ‰¾æ¡ˆä¾‹ |
| `by_scenario` | æŒ‰åœºæ™¯åˆ†ç±»çš„æ¡ˆä¾‹ | Composeræ ¹æ®éœ€æ±‚åœºæ™¯æŸ¥æ‰¾æ¡ˆä¾‹ |
| `usage_count` | ä½¿ç”¨æ¬¡æ•° | ç»Ÿè®¡æ¡ˆä¾‹å—æ¬¢è¿ç¨‹åº¦ |
| `avg_result_quality` | ä½¿ç”¨æ­¤æ¡ˆä¾‹åçš„å¹³å‡äº§å‡ºè´¨é‡ | ä¼˜åŒ–æ¡ˆä¾‹æ’åº |

### å¦‚ä½•ä»åé¦ˆä¸­ä¼˜åŒ–

#### æ¡ˆä¾‹æ•ˆæœè¿½è¸ª

```python
def track_example_usage(run_data):
    """
    è¿½è¸ªæ¡ˆä¾‹ä½¿ç”¨æ•ˆæœ
    """
    example_index = read_json('.state/indices/example-index.json')
    
    # è·å–æœ¬æ¬¡ä½¿ç”¨çš„æ¡ˆä¾‹
    disclosed_examples = run_data['disclosed_context']['examples']
    result_quality = run_data['output']['quality_score']
    
    # æ›´æ–°æ¯ä¸ªæ¡ˆä¾‹çš„æ•ˆæœç»Ÿè®¡
    for example_file in disclosed_examples:
        # åœ¨ç´¢å¼•ä¸­æ‰¾åˆ°æ­¤æ¡ˆä¾‹
        for feature, data in example_index['by_feature'].items():
            for quality_level in ['excellent', 'average']:
                for ex in data[quality_level]:
                    if ex['file'] == example_file:
                        # æ›´æ–°ä½¿ç”¨è®¡æ•°
                        ex['usage_count'] += 1
                        
                        # æ›´æ–°å¹³å‡äº§å‡ºè´¨é‡ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
                        old_avg = ex.get('avg_result_quality', result_quality)
                        count = ex['usage_count']
                        new_avg = (old_avg * (count - 1) + result_quality) / count
                        ex['avg_result_quality'] = round(new_avg, 2)
                        
                        # æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
                        ex['last_used'] = now()
    
    # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
    write_json('.state/indices/example-index.json', example_index)
```

#### æ¡ˆä¾‹æ’åºä¼˜åŒ–

```python
def optimize_example_order(example_index):
    """
    æ ¹æ®æ•ˆæœé‡æ–°æ’åºæ¡ˆä¾‹
    """
    for feature, data in example_index['by_feature'].items():
        for quality_level in ['excellent', 'average']:
            examples = data[quality_level]
            
            # æŒ‰å¹³å‡äº§å‡ºè´¨é‡é™åºæ’åº
            examples.sort(
                key=lambda ex: (
                    ex.get('avg_result_quality', 0),
                    ex.get('usage_count', 0)
                ),
                reverse=True
            )
            
            data[quality_level] = examples
    
    return example_index
```

### å¦‚ä½•å½±å“æŠ«éœ²

**Produceræ ¹æ®ç‰¹å¾æƒé‡å’Œæ¡ˆä¾‹ç´¢å¼•æŠ«éœ²æ¡ˆä¾‹**ï¼š

```python
def disclose_examples(feature_weights, example_index):
    """
    æ ¹æ®ç‰¹å¾æƒé‡æŠ«éœ²ç›¸å…³æ¡ˆä¾‹
    """
    disclosed = []
    
    for feature, data in feature_weights['weights'].items():
        weight = data['value']
        
        if weight >= 0.80:
            # æŠ«éœ²3ä¸ªä¼˜ç§€æ¡ˆä¾‹
            examples = example_index['by_feature'][feature]['excellent'][:3]
            disclosed.extend([ex['file'] for ex in examples])
            
        elif weight >= 0.65:
            # æŠ«éœ²2ä¸ªä¼˜ç§€æ¡ˆä¾‹
            examples = example_index['by_feature'][feature]['excellent'][:2]
            disclosed.extend([ex['file'] for ex in examples])
            
        elif weight >= 0.50:
            # æŠ«éœ²1ä¸ªä¼˜ç§€æ¡ˆä¾‹
            examples = example_index['by_feature'][feature]['excellent'][:1]
            disclosed.extend([ex['file'] for ex in examples])
    
    # å»é‡
    disclosed = list(set(disclosed))
    
    # åŠ è½½æ¡ˆä¾‹å†…å®¹
    example_contents = [
        read_file(f'knowledge/examples/excellent/{file}')
        for file in disclosed
    ]
    
    return example_contents
```

## ğŸ¨ pattern-index.json - æ¨¡å¼å¼•ç”¨ç´¢å¼•

### æ–‡ä»¶ç»“æ„

**ä½ç½®**ï¼š`.state/indices/pattern-index.json`

**æ ¼å¼**ï¼š

```json
{
  "version": "1.0.0",
  "last_updated": "2026-01-15T10:30:00Z",
  "patterns": {
    "zero_coupling": {
      "file": "zero-coupling.md",
      "priority": 0.92,
      "applicable_scenarios": [
        "component_design",
        "system_architecture"
      ],
      "reference_count": 15,
      "success_rate": 0.88,
      "avg_quality_improvement": 0.15,
      "last_referenced": "2026-01-14T10:00:00Z"
    },
    "event_driven": {
      "file": "event-driven.md",
      "priority": 0.85,
      "applicable_scenarios": [
        "game_flow",
        "ui_interaction"
      ],
      "reference_count": 12,
      "success_rate": 0.82,
      "avg_quality_improvement": 0.12
    },
    "component_based": {
      "file": "component-based.md",
      "priority": 0.80,
      "applicable_scenarios": [
        "component_design",
        "modularity"
      ],
      "reference_count": 10,
      "success_rate": 0.79,
      "avg_quality_improvement": 0.10
    }
  },
  "scenario_patterns": {
    "component_design": [
      "zero_coupling",
      "component_based",
      "single_responsibility"
    ],
    "system_architecture": [
      "zero_coupling",
      "layered_architecture",
      "dependency_injection"
    ]
  }
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | è¯´æ˜ | ç”¨é€” |
|-----|------|------|
| `priority` | æ¨¡å¼ä¼˜å…ˆçº§ | ä¸ç‰¹å¾æƒé‡åŒæ­¥ |
| `applicable_scenarios` | é€‚ç”¨åœºæ™¯ | åœºæ™¯åŒ¹é… |
| `reference_count` | è¢«å¼•ç”¨æ¬¡æ•° | ç»Ÿè®¡å—æ¬¢è¿åº¦ |
| `success_rate` | æˆåŠŸç‡ï¼ˆäº§å‡ºè´¨é‡>=0.80çš„æ¯”ä¾‹ï¼‰ | è¯„ä¼°æ¨¡å¼æœ‰æ•ˆæ€§ |
| `avg_quality_improvement` | å¹³å‡è´¨é‡æå‡ | æ¨¡å¼å¸¦æ¥çš„è´¨é‡å¢ç›Š |

### å¦‚ä½•ä»åé¦ˆä¸­ä¼˜åŒ–

#### æ¨¡å¼æ•ˆæœè¿½è¸ª

```python
def track_pattern_effectiveness(run_data):
    """
    è¿½è¸ªæ¨¡å¼ä½¿ç”¨æ•ˆæœ
    """
    pattern_index = read_json('.state/indices/pattern-index.json')
    
    disclosed_patterns = run_data['disclosed_context']['patterns']
    result_quality = run_data['output']['quality_score']
    
    for pattern_name in disclosed_patterns:
        pattern = pattern_index['patterns'][pattern_name]
        
        # æ›´æ–°å¼•ç”¨è®¡æ•°
        pattern['reference_count'] += 1
        
        # æ›´æ–°æˆåŠŸç‡
        is_success = result_quality >= 0.80
        old_success_rate = pattern['success_rate']
        count = pattern['reference_count']
        new_success_rate = (
            old_success_rate * (count - 1) + (1 if is_success else 0)
        ) / count
        pattern['success_rate'] = round(new_success_rate, 2)
        
        # æ›´æ–°æœ€åå¼•ç”¨æ—¶é—´
        pattern['last_referenced'] = now()
    
    write_json('.state/indices/pattern-index.json', pattern_index)
```

#### æ¨¡å¼ä¼˜å…ˆçº§åŒæ­¥

```python
def sync_pattern_priority(feature_weights, pattern_index):
    """
    å°†ç‰¹å¾æƒé‡åŒæ­¥åˆ°æ¨¡å¼ä¼˜å…ˆçº§
    """
    for pattern_name, pattern in pattern_index['patterns'].items():
        # å‡è®¾æ¨¡å¼åä¸ç‰¹å¾åä¸€è‡´
        if pattern_name in feature_weights['weights']:
            feature_data = feature_weights['weights'][pattern_name]
            pattern['priority'] = feature_data['value']
    
    write_json('.state/indices/pattern-index.json', pattern_index)
```

### å¦‚ä½•å½±å“æŠ«éœ²

**Produceræ ¹æ®æƒé‡å’Œåœºæ™¯æŠ«éœ²æ¨¡å¼**ï¼š

```python
def disclose_patterns(feature_weights, pattern_index, scenario):
    """
    æ ¹æ®ç‰¹å¾æƒé‡å’Œåœºæ™¯æŠ«éœ²æ¨¡å¼æ–‡æ¡£
    """
    disclosed = []
    
    # 1. æ ¹æ®åœºæ™¯è·å–æ¨èæ¨¡å¼
    if scenario in pattern_index['scenario_patterns']:
        recommended = pattern_index['scenario_patterns'][scenario]
    else:
        recommended = []
    
    # 2. æŒ‰ç‰¹å¾æƒé‡æŠ«éœ²
    for feature, data in feature_weights['weights'].items():
        weight = data['value']
        
        if feature not in pattern_index['patterns']:
            continue
        
        pattern = pattern_index['patterns'][feature]
        
        if weight >= 0.85:
            # å®Œæ•´æŠ«éœ²
            content = read_file(f'knowledge/patterns/{pattern["file"]}')
            disclosed.append({
                'pattern': feature,
                'level': 'full',
                'content': content,
                'recommended': feature in recommended
            })
            
        elif weight >= 0.70:
            # æ‘˜è¦æŠ«éœ²
            content = extract_summary(
                read_file(f'knowledge/patterns/{pattern["file"]}')
            )
            disclosed.append({
                'pattern': feature,
                'level': 'summary',
                'content': content
            })
            
        elif weight >= 0.50:
            # ç®€è¦æåŠ
            disclosed.append({
                'pattern': feature,
                'level': 'brief',
                'content': pattern['file']
            })
    
    return disclosed
```

## ğŸ”„ ç´¢å¼•ä¹‹é—´çš„ååŒ

ä¸‰ä¸ªç´¢å¼•ä¸æ˜¯ç‹¬ç«‹å·¥ä½œï¼Œè€Œæ˜¯ååŒå½±å“æŠ«éœ²ç­–ç•¥ï¼š

```python
def comprehensive_disclosure(task, indices):
    """
    ç»¼åˆä¸‰ä¸ªç´¢å¼•è¿›è¡ŒæŠ«éœ²
    """
    feature_weights = indices['feature_weights']
    example_index = indices['example_index']
    pattern_index = indices['pattern_index']
    
    context = {
        'patterns': [],
        'examples': [],
        'total_tokens': 0
    }
    
    # 1. è¯†åˆ«ä»»åŠ¡åœºæ™¯
    scenario = identify_scenario(task)
    
    # 2. æŒ‰ç‰¹å¾æƒé‡æŠ«éœ²æ¨¡å¼
    patterns = disclose_patterns(feature_weights, pattern_index, scenario)
    context['patterns'] = patterns
    context['total_tokens'] += sum(count_tokens(p['content']) for p in patterns)
    
    # 3. æŒ‰ç‰¹å¾æƒé‡æŠ«éœ²æ¡ˆä¾‹
    examples = disclose_examples(feature_weights, example_index)
    context['examples'] = examples
    context['total_tokens'] += sum(count_tokens(ex) for ex in examples)
    
    # 4. æ§åˆ¶æ€»tokenæ•°ï¼ˆé˜²æ­¢è¶…é™ï¼‰
    MAX_TOKENS = 8000
    if context['total_tokens'] > MAX_TOKENS:
        # ä¼˜å…ˆä¿ç•™é«˜æƒé‡å†…å®¹
        context = trim_context(context, MAX_TOKENS, feature_weights)
    
    return context
```

## ğŸ“Š ç´¢å¼•ä¼˜åŒ–æ•ˆæœå¯è§†åŒ–

### æƒé‡è¿›åŒ–è¶‹åŠ¿

```
ç‰¹å¾æƒé‡è¿›åŒ–ï¼ˆ50è½®å¾ªç¯ï¼‰

zero_coupling:  0.50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.92
modularity:     0.50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     0.85
naming:         0.50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              0.65
error_handling: 0.50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 0.60
testability:    0.50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   0.58
performance:    0.50 â–ˆâ–ˆâ–ˆâ–ˆ                     0.45
comments:       0.50 â–ˆâ–ˆâ–ˆ                      0.35

â†’ æ˜æ˜¾åˆ†åŒ–ï¼šé«˜ç›¸å…³ç‰¹å¾æƒé‡ä¸Šå‡ï¼Œä½ç›¸å…³ç‰¹å¾æƒé‡ä¸‹é™
```

### è´¨é‡æå‡æ›²çº¿

```
äº§å‡ºè´¨é‡ vs å¾ªç¯è½®æ•°

è´¨é‡
0.90 |                           â—â—â—â—â—
     |                       â—â—â—â—
0.85 |                   â—â—â—â—
     |               â—â—â—â—
0.80 |           â—â—â—â—
     |       â—â—â—â—
0.75 |   â—â—â—â—
     | â—â—â—
0.70 |â—â—
     |â—
0.65 |â—
     +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ å¾ªç¯
      1  5  10 15 20 25 30 35 40 45 50

é˜¶æ®µ1(1-10)ï¼šæ¢ç´¢æœŸï¼Œè´¨é‡æ³¢åŠ¨
é˜¶æ®µ2(11-30)ï¼šä¼˜åŒ–æœŸï¼Œç¨³æ­¥ä¸Šå‡
é˜¶æ®µ3(31-50)ï¼šç¨³å®šæœŸï¼Œé«˜ä½ç»´æŒ
```

## ğŸ”§ ç´¢å¼•ç®¡ç†å·¥å…·

### å¤‡ä»½ç´¢å¼•

```bash
#!/bin/bash
# backup-indices.sh

DATE=$(date +%Y%m%d-%H%M%S)
BACKUP_DIR="backups/indices-$DATE"

mkdir -p "$BACKUP_DIR"
cp -r .state/indices/* "$BACKUP_DIR/"

echo "ç´¢å¼•å·²å¤‡ä»½åˆ° $BACKUP_DIR"
```

### é‡ç½®ç´¢å¼•

```bash
#!/bin/bash
# reset-indices.sh

echo "è­¦å‘Šï¼šå³å°†é‡ç½®æ‰€æœ‰ç´¢å¼•åˆ°åˆå§‹çŠ¶æ€"
read -p "ç¡®è®¤ï¼Ÿ(yes/no): " confirm

if [ "$confirm" == "yes" ]; then
    # å¤‡ä»½å½“å‰ç´¢å¼•
    ./backup-indices.sh
    
    # é‡ç½®ç‰¹å¾æƒé‡
    cat > .state/indices/feature-weights.json << EOF
{
  "version": "1.0.0",
  "weights": {
    "zero_coupling": {"value": 0.50, "history": [0.50]},
    "modularity": {"value": 0.50, "history": [0.50]},
    "naming": {"value": 0.50, "history": [0.50]}
  }
}
EOF
    
    echo "ç´¢å¼•å·²é‡ç½®"
fi
```

### æŸ¥çœ‹ç´¢å¼•çŠ¶æ€

```bash
#!/bin/bash
# show-indices-status.sh

echo "=== ç‰¹å¾æƒé‡çŠ¶æ€ ==="
jq '.weights | to_entries | sort_by(.value.value) | reverse | .[] | "\(.key): \(.value.value)"' \
   .state/indices/feature-weights.json -r

echo ""
echo "=== æ¡ˆä¾‹ç´¢å¼•ç»Ÿè®¡ ==="
jq '.metadata' .state/indices/example-index.json

echo ""
echo "=== æ¨¡å¼ç´¢å¼•ç»Ÿè®¡ ==="
jq '.patterns | length' .state/indices/pattern-index.json
```

## ğŸ“– ä¸‹ä¸€æ­¥

- **æŸ¥çœ‹å®Œæ•´å·¥ä½œæµ** â†’ [06-workflow.md](./06-workflow.md)
- **å­¦ä¹ è¿›åŒ–æœºåˆ¶** â†’ [07-evolution-mechanism.md](./07-evolution-mechanism.md)
- **å¼€å§‹å®æ–½** â†’ [08-implementation-guide.md](./08-implementation-guide.md)

---

**è¿”å›** â†’ [æ¡†æ¶æ–‡æ¡£é¦–é¡µ](./README.md)
